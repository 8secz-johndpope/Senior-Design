from bs4 import BeautifulSoup as bs
from GyazoObject import GyazoObj
import os
import pandas as pd
import requests
from selenium import webdriver
from selenium.webdriver.firefox.options import Options
import shutil
import time
import urllib

icos = pd.read_csv('whitepapers_original.csv')

#TODO
'''
loop through every ico
if no images throw red flag
if no social media throw red flag
discuss what would constitute a red flag on a reverse image search
'''

class Google():
    def __init__(self):
        self.google_path = 'images.google.com/searchbyimage?image_url='
        self.gyazo = GyazoObj()
        self.root_dir = '/Users/noahquinones/Desktop/Senior_Project/Senior-Design/Reverse_Image_Search/data/'
        self.geckodrv = '/Users/noahquinones/Desktop/Senior_Project/Senior-Design/Reverse_Image_Search/geckodriver'

    def get_df(self, d):
        target = self.root_dir + d
        if os.path.isdir(target):
            os.chdir(target)
            print(d)
            if os.path.exists(d + '.csv'):
                df = pd.read_csv(d + '.csv')
                return df
            else:
                temp_df = pd.DataFrame()

    def useSelenium(self, path):
        options = Options()
        options.headless = True
        driver = webdriver.Firefox(options=options, executable_path=self.geckodrv)
        driver.get(path)
        target = driver.find_element_by_id('cnt')
        html = target.get_attribute('innerHTML')
        driver.quit()
        return html

    def reverseImageSearch(self, gyazo_url):
        google_path = 'https://images.google.com/searchbyimage?image_url='
        full_path = google_path + gyazo_url
        html = self.useSelenium(full_path)
        soup = bs(html, 'lxml')
        targets = soup.find_all('div', {'class':'g'})

    def verifyAll(self):
        dirs = sorted(os.listdir(self.root_dir), key=lambda x: str.lower(x))
        for d in dirs:
            df = self.get_df(d)
            if df.empty:
                print('RED FLAG')
            else:
                for index, row in df.iterrows():
                    img_file = row['Image File']
                    if img_file != 'N\A':
                        img_obj = self.gyazo.upload(img_file)
                        url = img_obj.url
                        self.reverseImageSearch(url)
                        break
                    else:
                        print('MIGHT BE RED FLAG')
                break
                os.chdir('..')

    #Attempt #3134: this is getting annoying...
    def search_crypto_name_in_results(self, cryto_name, path):
        try:
            #need to setup for all social media? lets setup linkedin first 
            #Method 1
            #create password manager
            pass_mngr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
            #should definitely secure this with a secret, or just use proxy accounts for now lets leave unsecure 
            pass_mngr.add_password(None, path, 'nquinone', 'soccer01') #yes, this is bad but w/e for right now
            #create handler to deal with sites that send back 401
            auth_handler = urllib.request.HTTPBasicAuthHandler(pass_mngr)
            #OpenerDirector instance
            opener = urllib.request.build_opener(auth_handler)
            #Use opener for URL fetch
            opener.open(path)
            #install opener to tie urlopen to opener
            urllib.request.install_opener(opener)
            #create request, allow browser to identify itself through user-agent header 
            req = urllib.request.Request(path, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'})
            #make urlopen call on reques object and read raw html
            raw_html = urllib.request.urlopen(req).read()
            print(raw_html)
        #Attempt 2:
        # base64string = base64.b64encode('%s:%s' % ('nquinone', 'soccer01'))
        # req.add_header("Authorization", "Basic %s" % base64string)

        # raw_html = urlopen(req).read()
        # print(raw_html)
        except:
            #flag team member here
            print('No page could be accessed!')
            return 
        soup = bs(raw_html, 'lxml')
        print(soup)
    #Note, possibly consider searching LinkedIn names using selenium 
    def verify_social_media(self):
        #return list of directories generated by icobench.py
        dirs = sorted(os.listdir(self.root_dir), key=lambda x: str.lower(x))
        #for every directory in the list grab corresponding csv file
        for d in dirs:
            df = self.get_df(d)
            #empty-> no social media (or images) -> throw RED FLAG 
            if df.empty:
                print('RED FLAG') #need to throw red flag (should be considered highly suspicious)
            else:
                #else lets examine csv contents
                for index, row in df.iterrows():
                    social_media_file = row['Social Media File']
                    #no social media file-> throw red flag? (lower in severity then no csv)
                    if social_media_file == 'N/A':
                        print('POSSIBLE RED FLAG')
                    else:
                        social_media_links = []
                        with open(social_media_file, 'r') as s_m_f:
                            for line in s_m_f:
                                social_media_links.append(line[line.find('|')+1:line.rfind('\n')]) #ewwwwwww, nasty one liner
                        #iterate through social media-links
                        #TODO: need to create Team (or Person, however this would be heavy) object to maintain flags
                        crypto_mentioned = False
                        for path in social_media_links:
                            self.search_crypto_name_in_results(d, path)

                break
                os.chdir('..')

    def verifyICO(self, ico_name):
        # verify the legitamacy of an individual ico
        pass

client = Google()
client.verifyAll()
client.verify_social_media()
